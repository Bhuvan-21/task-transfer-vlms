<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Understanding Task Transfer in Vision-Language Models - Bhuvan Sachdeva, Karan Uppal, Abhinav Java, Vineeth N. Balasubramanian">
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <meta name="author" content="Bhuvan Sachdeva, Karan Uppal, Abhinav Java, Vineeth N. Balasubramanian">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <meta property="og:title" content="Understanding Task Transfer in Vision-Language Models">
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Understanding Task Transfer in Vision-Language Models - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <meta name="twitter:title" content="Understanding Task Transfer in Vision-Language Models">
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Understanding Task Transfer in Vision-Language Models">
  <meta name="citation_author" content="Sachdeva, Bhuvan">
  <meta name="citation_author" content="Uppal, Karan">
  <meta name="citation_author" content="Java, Abhinav">
  <meta name="citation_author" content="Balasubramanian, Vineeth N.">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>Understanding Task Transfer in Vision-Language Models</title>
  <link rel="icon" href="data:,">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Understanding Task Transfer in Vision-Language Models",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "Bhuvan Sachdeva",
        "affiliation": {
          "@type": "Organization",
          "name": "Microsoft Research"
        }
      },
      {
        "@type": "Person",
        "name": "Karan Uppal",
        "affiliation": {
          "@type": "Organization",
          "name": "Microsoft Research"
        }
      },
      {
        "@type": "Person",
        "name": "Abhinav Java",
        "affiliation": {
          "@type": "Organization",
          "name": "Microsoft Research"
        }
      },
      {
        "@type": "Person",
        "name": "Vineeth N. Balasubramanian",
        "affiliation": {
          "@type": "Organization",
          "name": "Microsoft Research"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>

  <script>
    window.MathJax = {
      tex: { inlineMath: [['$','$'], ['\\(','\\)']] },
      svg: { fontCache: 'global' }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Understanding Task Transfer in Vision-Language Models</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a>Bhuvan Sachdeva</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a>Karan Uppal</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a>Abhinav Java</a><sup>*</sup>,</span>
                    <span class="author-block">
                      <a>Vineeth N. Balasubramanian</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Microsoft Research India<br>2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <!-- <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- Replaced teaser video with image -->
      <img src="static/images/teaser_figure.png" alt="Teaser overview figure" loading="lazy" class="teaser-image">
      <h2 class="subtitle has-text-centered">
        Vision-Language Models (VLMs) are usually finetuned on multiple tasks with little knowledge about how such finetuning affects a model’s performance on other tasks. Hence we aim to explore:
        How does finetuning on one visual perception task affect performance on other tasks?
      </h2>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Vision-Language Models (VLMs) perform well on multimodal benchmarks but lag behind humans and specialized models on visual perception tasks like depth estimation or object counting. Finetuning on one task can unpredictably affect performance on others, making task-specific finetuning challenging. In this paper, we address this challenge through a systematic study of task transferability. We examine how finetuning a VLM on one perception task affects its zero-shot performance on others. To quantify these effects, we introduce Perfection Gap Factor (PGF), a metric that captures both the breadth and magnitude of transfer. Using three open-weight VLMs evaluated across 13 perception tasks, we construct a task-transfer graph that reveals previously unobserved relationships among perception tasks. Our analysis uncovers patterns of positive and negative transfer, identifies groups of tasks that mutually influence each other, organizes tasks into personas based on their transfer behavior, and demonstrates how PGF can guide data selection for more efficient training. These findings highlight both opportunities for positive transfer and risks of negative interference, offering actionable guidance for advancing VLMs.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- PGF Score Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Perfection Gap Factor (PGF) Score</h2>
        <div class="content has-text-justified">

          <p>
            Understanding how finetuning on one task affects performance on another—<strong>task transferability</strong>—is central to analyzing the behavior of Vision-Language Models (VLMs). Traditional transfer metrics often fail to account for how close a target task already is to its ceiling performance: a small improvement near saturation may be far more meaningful than a large improvement on a task with plenty of remaining headroom.
          </p>

          <p>
            To address this limitation, we introduce the <strong>Perfection Gap Factor (PGF)</strong>, a normalized measure that captures how much of the <em>remaining</em> performance gap on a target task is closed by finetuning on a source task. PGF enables fair comparison of transfer effects across tasks with different difficulty levels and performance ceilings.
          </p>

          <p>
            Consider a VLM <strong>M</strong> finetuned on a source task <strong>T<sub>i</sub></strong> (denoted as <strong>M(T<sub>i</sub>)</strong>) and evaluated on a target task <strong>T<sub>j</sub></strong>, which has an upper-bound or ceiling performance <strong>U<sub>j</sub></strong>. Let <strong>Acc(M, T)</strong> denote the accuracy of model <strong>M</strong> on task <strong>T</strong>.
          </p>

          <div class="has-text-centered" style="margin: 1.5em 0;">
            <div class="math" style="display:inline-block;padding:1em;border-radius:8px;">
              $$\mathrm{PGF}_{i \to j}=\frac{\mathrm{Acc}(M(T_i),\,T_j) - \mathrm{Acc}(M,\,T_j)}{U_j - \mathrm{Acc}(M,\,T_j)}$$
            </div>
          </div>

          <p>
            Here, the numerator measures the change in performance on <strong>T<sub>j</sub></strong> due to finetuning on <strong>T<sub>i</sub></strong>, while the denominator captures the <em>remaining gap</em> to the ceiling <strong>U<sub>j</sub></strong>. A larger gap means more room to improve, while a smaller gap indicates a saturated task where improvements are harder.
          </p>

          <p>
            <strong>Interpretation:</strong>  
            A positive PGF indicates beneficial transfer, and a negative PGF indicates harmful transfer. Values near <strong>1</strong> reflect strong positive transfer (closing most of the remaining gap), while values near <strong>-1</strong> indicate substantial negative transfer. PGF therefore provides a calibrated and comparable view of cross-task influence in VLM finetuning.
          </p>

        </div>
      </div>
    </div>
  </div>
</section>

<div class="item has-text-centered">
  <figure class="image" style="margin: 0 auto; max-width: 900px;">
    <img src="static/images/all_pgf.png" alt="Cross-task transfer heatmaps" loading="lazy" />
  </figure>

  <h2 class="subtitle has-text-centered" style="max-width: 900px; margin: 1rem auto;">
    Cross-task transferability across Qwen-2.5-VL models (3B, 7B, 32B): Each heatmap visualizes
    the Perfection Gap Factor (PGF) between all pairs of source (rows) and target (columns)
    tasks. Green indicates positive transfer, while red indicates negative transfer.
  </h2>
</div>




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <img src="static/images/presentation_overview.png" alt="Presentation overview figure" loading="lazy">
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-plot1">
          <img src="static/images/plot1.png" alt="Plot 1: Transfer graph" loading="lazy">
        </div>
        <div class="item item-plot2">
          <img src="static/images/plot2.png" alt="Plot 2: Positive vs negative transfer" loading="lazy">
        </div>
        <div class="item item-plot3">
          <img src="static/images/plot3.png" alt="Plot 3: PGF-guided data selection" loading="lazy">
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      
      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{Sachdeva2025TaskTransfer,
  title={Understanding Task Transfer in Vision-Language Models},
  author={Bhuvan Sachdeva and Karan Uppal and Abhinav Java and Vineeth N. Balasubramanian},
  journal={arXiv preprint},
  year={2025},
  url={https://arxiv.org/abs/1234.56789}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Built using the 
            <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>,
            adapted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.  
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
  </html>
